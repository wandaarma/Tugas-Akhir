# -*- coding: utf-8 -*-
"""Tugas Akhir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_A9nRJQFzrQVrQDR5SrDZHi-r4dXoL6R
"""

# Import Library Python
import numpy as np
import pandas as pd
from flask import Flask, request, render_template
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from PyPDF2 import PdfReader
from nltk.corpus import stopwords
import re
import os
import nltk

# Initialize Flask app
app = Flask(__name__)

# Download stopwords
nltk.download('stopwords')

"""# Extract CV Text"""

# Function to preprocess CV text
def preprocess_cv(text1):
    # Lowercase
    text1 = text1.lower()
    # Remove symbols
    pattern = r'[^A-Za-z\s]'
    text1 = re.sub(pattern, '', text1)
    # Remove stopwords
    stop = set(stopwords.words('english'))
    text1 = ' '.join([word for word in text1.split() if word not in stop])
    return text1

# Function to extract text from PDF
def extract_text_from_pdf(file_path):
    text = ''
    try:
        with open(file_path, 'rb') as file:
            reader = PdfReader(file)
            num_pages = len(reader.pages)
            for page_num in range(num_pages):
                text += reader.pages[page_num].extract_text()
    except Exception as e:
        print(f"Error reading PDF file '{file_path}': {str(e)}")
    return text

"""# Recommendation"""

# Initialize vectorizer and calculate TF-IDF vectors
postings = pd.read_csv('postings.csv')
clean_postings = pd.read_csv('clean_postings.csv')
vectorizer = TfidfVectorizer(min_df=10, max_df=0.8, sublinear_tf=True, use_idf=True)
job_vectors = vectorizer.fit_transform(clean_postings['combined'])

def recommend_jobs(user_cv, desired_job_description, top_n=5):
    user_input = user_cv + " " + desired_job_description
    user_input_vector = vectorizer.transform([user_input])
    similarity_scores = cosine_similarity(user_input_vector, job_vectors).flatten()
    top_indices = similarity_scores.argsort()[-top_n:][::-1]

    recommendations = []
    for index in top_indices:
        recommendations.append({
            'ID': postings.iloc[index]['job_id'],
            'Company Name': postings.iloc[index]['company_name'],
            'Title': postings.iloc[index]['title'],
            'Description': postings.iloc[index]['description'],
            'Location': postings.iloc[index].get('location', 'N/A'),  # Add location if available
            'Work Type': postings.iloc[index].get('work_type', 'N/A'),  # Add work type if available
            'Similarity Score': similarity_scores[index]
        })
    return recommendations

# Define routes
@app.route('/')
def home():
    return render_template('form.html')

@app.route('/recommend', methods=['POST'])
def recommend():
    job_description = request.form['job_description']
    cv_file = request.files['cv']
    
    if cv_file:
        file_path = os.path.join('uploads', cv_file.filename)
        cv_file.save(file_path)
        cv_text = extract_text_from_pdf(file_path)
        os.remove(file_path)  # Remove the temporary file
        preprocessed_cv = preprocess_cv(cv_text)
        print(preprocessed_cv)
        recommendations = recommend_jobs(preprocessed_cv, job_description)
        return render_template('recommendations.html', recommendations=recommendations)
    else:
        return 'No CV uploaded', 400

# Run the app
if __name__ == '__main__':
    if not os.path.exists('uploads'):
        os.makedirs('uploads')
    app.run(debug=True)
